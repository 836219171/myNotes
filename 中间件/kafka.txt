1 kafka的leader选举是通过broad_id注册的先后顺序确定的
2 kafka官方文档 http://kafka.apache.org/documentation/

kafka-console-producer.sh --broker-list localhost:9092 --topic zhhtest

kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic zhhtest --from-beginning

kafka的实践经验
1 最好用外置的zk
2 如果外网访问的时候 需要配置这个 注释的example里没有advertised，所以不行。客户端都启动不起来 
要有advertised前缀 advertised.listeners=PLAINTEXT://211.159.161.31:9092
参考 https://www.jianshu.com/p/3f986c8eb3f9

消费者提交方式
1 自动提交位移
2 手动提交当前位移
3 手动异步提交当前位移
4 手动异步提交当前位移带回调
5 混合同步与异步提交位移


手动提交结束出现异常的时候，不要尝试重新提交，会造成数据不一致的现象 

kafka数据防丢失配置
Kafka 弄丢了数据
这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。大家想想，要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，不就少了一些数据？这就丢了一些数据啊。

生产环境也遇到过，我们也是，之前 Kafka 的 leader 机器宕机了，将 follower 切换为 leader 之后，就会发现说这个数据就丢了。

所以此时一般是要求起码设置如下 4 个参数：

给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
在 producer 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。
我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。

生产者会不会弄丢数据？
如果按照上述的思路设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

kafka总结不错的博文
https://www.cnblogs.com/swordfall/p/10193336.html